\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{xcolor}
\usepackage{adjustbox}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{mathptmx}
\usepackage[T1]{fontenc}

\usetikzlibrary{shapes.geometric, arrows, positioning}

\tikzstyle{phase} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=blue!20]
\tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!20]
\tikzstyle{arrow} = [thick,->,>=stealth]


\titleformat{\section}[hang]{\bfseries\large\bold}{\thesection.}{em}{\MakeUppercase}
\titlespacing*{\section}{0pt}{1\baselineskip}{1\baselineskip}


\hypersetup{
    colorlinks=true, % Set to true for colored text instead of boxes
    linkcolor=blue,  % Color of links
    filecolor=magenta,      
    urlcolor=black,
    citecolor=green,
    pdfborder={0 0 0} % Removes the border completely
}

\geometry{margin=1in}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\includegraphics[height=0.8cm]{logos/iitj_logo.png} \hspace{0.5cm} Summer RAID 2025}
\fancyhead[R]{FileNest Framework \hspace{0.5cm} \includegraphics[height=0.8cm]{logos/raid_logo.png}}
\fancyfoot[C]{Page \thepage\ of \pageref{LastPage}}

\titleformat{\section}{\Large\bfseries\color{blue!80!black}}{\thesection}{1em}{}
\titleformat{\subsection}{\large\bfseries}{\thesubsection}{1em}{}

\begin{document}

\begin{titlepage}
\centering

% Central Logo at the top
    \begin{center}
    \begin{tikzpicture}
        % Create a rounded rectangle clip path
        \begin{scope}
            \clip[rounded corners=10pt] (0,0) rectangle (0.6\textwidth,0.6\textwidth);
            % Place the image inside the clipped area
            \node at (0.3\textwidth,0.3\textwidth) {
                \includegraphics[width=0.7\textwidth]{logos/fileNest-11.png}
            };
        \end{scope}
    \end{tikzpicture}

    % \begin{tikzpicture}
    %     \node[draw=primaryblue, rounded corners=10pt, line width=5pt] {
    %         \includegraphics[width=0.6\textwidth]{fileNest-8.jpg}
    %     };
    % \end{tikzpicture}

    % \includegraphics[width=0.8\textwidth, frame, roundcorners=10pt]{fileNest-8.jpg}
    \end{center}
    % \vspace{2cm}

\vspace*{1cm}
{\huge\color{blue!80!black} \textbf{FileNest Framework}}\\[0.3cm]
{\Large A Multi-Modal Intelligent Search Engine over Decentralized Data
}\\[0.2cm]

\vspace*{2cm}

{\huge\bfseries Summer RAID '25}\\[0.5cm]
% {\Large Research and Innovation Development Program}\\[0.3cm]
{\large Project Proposal}\\[1.5cm]
\vspace*{1cm}

% {\large for Decentralized Content Ecosystems}\\[2cm]


{\large
\begin{tabular}{|l|l|}
\hline
\textbf{Submission Date} & June 5, 2025 \\
\hline
\textbf{Program} & Summer RAID 2025 \\
\hline
\textbf{Project Domain} &  Multimodal AI and Semantic Retrieval + Peer-to-Peer Networks\\
\hline
\textbf{Mentor} & {Lakshya Jain  \textbar{} Aradhya Mahajan \textbar{} Laksh Mendpara} \\
\hline
\textbf{Institution} & IIT Jodhpur \\
\hline
\end{tabular}
}


\end{titlepage}

\section{Project Overview}
\textbf{FileNest Framework: A Multi-Modal Intelligent Search Engine over Decentralized Data}

\subsection{Executive Summary}
FileNest Framework represents a paradigm shift in information retrieval and content discovery, leveraging cutting-edge artificial intelligence and distributed computing technologies. The platform addresses the growing need for intelligent, scalable, and semantic search capabilities across diverse content types including text documents, research papers, images, and multimedia content. By implementing a peer-to-peer distributed architecture with advanced AI-powered understanding, FileNest eliminates traditional bottlenecks while providing unprecedented search accuracy and performance.

\section{System Overview (Work in Progress)}

At a high level, FileNest consists of a hierarchical distributed tagging system that combines intelligent embedding generation with peer-to-peer routing mechanisms. The system operates through four distinct phases that work together to create a scalable, intelligent, and decentralized search infrastructure.

\subsection{Architecture Components}

\subsubsection{Bootstrap Phase (Depth 1 Tagging Vector Creation)}
\begin{itemize}
    \item Generate a set of sample embeddings from representative files across the network
    \item Cluster or otherwise select 100 initial “Depth 1 Tagging Vectors” (D1TVs).
    \item Distribute those 100 D1TVs (and their responsibility assignments) to all peers.
\end{itemize}

\subsubsection{Local Indexing Phase (per peer, for each file)}
\begin{itemize}
    \item A peer generates an embedding (n-dimensional float vector) for a file in its shared directory.
    \item It finds the most similar Depth 1 tagging vector (via cosine similarity).
    \item It “routes” the file metadata (peerID, fileURI, embedding) to the responsible Depth 1 peer, incrementing that D1TV’s count and retraining the D1TV vector asynchronously.
    \item That peer (Depth 1) repeats the same logic at Depth 2, and so on, until Depth 4. At Depth 4, the file metadata is finally stored at the leaf peer.
\end{itemize}

\subsubsection{Continuous Training (Tagging Vector Updates)}
\begin{itemize}
    \item Whenever a new embedding is routed to an existing tagging vector (similarity > threshold), the tagging vector’s centroid is updated via a weighted mean function.
    % \begin{equation}
    % v_{new} = \frac{c_{old} \cdot v_{old} + e_{new}}{c_{old} + 1}, \quad c_{new} = c_{old} + 1
    % \end{equation}
    \item If no existing tagging vector at a given depth is similar enough (similarity < threshold), a new vector is created at that depth. A peer is assigned via DHT to own that new vector.
\end{itemize}

\subsubsection{Query Phase (from a client)}
\begin{itemize}
    \item The client computes an embedding for its query (text, image, etc.) using the same ML model.

    \item The client also specifies per-depth similarity thresholds.
    \item The embedding is sent to all Depth 1 peers. Each Depth 1 peer computes similarity vs. its tagging vectors; if the maximum similarity greater than the client’s Depth 1 threshold, that branch “survives,” otherwise it is pruned.

    \item The surviving Depth 1 peers forward the query to Depth 2 peers, applying the Depth 2 threshold, and so on down to Depth 4.
    
    \item Each Depth 4 (leaf) peer that is reached returns file matches (fileURI, originPeer, similarity). The client aggregates results.
\end{itemize}

\subsection{System Architecture Diagram}
\begin{center}
    \includegraphics[width=0.7\textwidth]{umls/high_flow.png}
\end{center}

\subsubsection{Local Indexing}
\begin{center}
    \includegraphics[width=0.7\textwidth]{architecture/Local_indexing.png}
\end{center}

\subsubsection{Network Indexing}
\begin{center}
    \includegraphics[width=0.7\textwidth]{architecture/network_indexing.png}
\end{center}

\section{Objective}

Current search and indexing solutions face significant limitations in handling diverse content types, providing semantic understanding, and scaling efficiently across distributed environments. Existing platforms like Elasticsearch, Apache Solr, and Algolia suffer from centralized architecture bottlenecks, limited multi-modal support, and high infrastructure costs that make them unsuitable for modern AI-powered applications.

In an age where most information access is mediated by centralized entities—search engines, cloud storage providers, content hosting platforms—we've grown used to convenience at the cost of control. These systems, while efficient, come with a host of problems:

\subsection{Problems Addressed}
\begin{itemize}
    \item \textbf{Data centralization} leads to privacy risks, data mining, and platform censorship.
    \item \textbf{Limited access} to information that goes against dominant narratives or is locked behind content policies
    \item \textbf{Insufficient Academic Integration}: Lack of specialized algorithms for research paper understanding, citation analysis, and scientific content discovery
    \item \textbf{Fragile hosting} models—where files and knowledge vanish when servers shut down or accounts are banned.
    \item \textbf{Growing mistrust} in the algorithmic filters that dictate what we see.
\end{itemize}

FileNest aims to flip that model. It provides an intelligent search engine that runs across a decentralized, peer-based network.
It combines the ease of intelligent discovery—like Google Drive Search or YouTube recommendations—with the resilience and freedom of P2P systems.

\subsection{Real-World Impact}

This opens up exciting possibilities for niche yet critical use-cases:

\begin{itemize}
    \item \textbf{Academic collaboration}: Labs or researchers can share files and papers directly, searchable across institutions without cloud lock-in.

    \item \textbf{Censorship-resistant content discovery}: Useful for journalists, archivists, or individuals seeking sensitive or restricted knowledge.

    \item \textbf{Decentralized knowledge commons}: Like a smarter, distributed version of torrenting — but semantically searchable.

    \item \textbf{Self-hosted file search across devices or teams}: Enabling secure internal discovery without exposing to external servers.

\end{itemize}

The core idea: Even though data is decentralized and scattered, FileNest makes discovering it as simple and powerful as searching Google — but without giving up ownership, privacy, or freedom.

\section{What We Are Trying to Achieve}

\subsection{Primary Objectives}
\begin{enumerate}
    \item \textbf{Performance Optimization}: Achieve 400-500\% improvement in indexing throughput and search response times compared to current implementation of local-first intelligent search
    \item \textbf{Multi-Modal Intelligence}: Develop advanced AI-powered content understanding for text, images, videos, PDFs and other file formats
    \item \textbf{Decentralized Architecture}: Build a peer-to-peer network system that creates fault tolerance and reduces central dependency
    \item \textbf{Academic Specialization}: Create sophisticated research paper analysis capabilities with citation networks and semantic understanding
    \item \textbf{Scalability Enhancement}: Enable enterprise-grade deployments supporting thousands of concurrent users
\end{enumerate}

\subsection{Technical Goals}
\begin{itemize}
    \item Reduce search latency from 800-1200ms to under 100ms
    \item Increase indexing throughput from 2-3 files/sec to 15-20 files/sec
    \item Support multi-modal content types with cross-modal search capabilities
    \item Implement consensus algorithms for data integrity
    \item Achieve storage efficiency with less than 20\% overhead
\end{itemize}

\section{Expected Outcome}

\subsection{Primary Deliverables}
\begin{enumerate}
    \item \textbf{Multi-Modal Search Engine}: Production-ready system supporting text, image, video, and PDF content with semantic understanding.
    \item \textbf{Research Paper Intelligence}: Specialized module for academic content analysis, including citation extraction and relationship mapping.
    \item \textbf{Distributed Computing Platform}: Peer-to-peer network architecture with consensus mechanisms and fault tolerance for high availability.
    \item \textbf{Natural Language Interface}: AI-powered query processing system enabling complex natural language searches with contextual understanding.
    \item \textbf{Performance Optimization Suite}: Advanced algorithms and caching mechanisms delivering sub-100ms search responses for optimal user experience.
    \item \textbf{DevOps Integration Framework}: Robust CI/CD pipelines, automated testing suites, and monitoring tools ensuring code quality, system reliability, and faster deployment cycles.
\end{enumerate}

\subsection{Measurable Outcomes}
\begin{tabularx}{\textwidth}{|X|X|X|}
\hline
\textbf{Metric} & \textbf{Current State} & \textbf{Expected Outcome} \\
\hline
Indexing Speed & 1 file/second & 15-20 files/second \\
\hline
Search Latency & 800-1200 milliseconds & Under 100 milliseconds \\
\hline
Content Types & All & All \\
\hline
Concurrent Users & Single user & 1000+ users \\
\hline
Storage Overhead & 85\% & Under 20\% \\
\hline
API Dependencies & 100\% external & 50\% self-reliant \\
\hline
\end{tabularx}

\subsection{Innovation Impact}
The project will establish new benchmarks for distributed search architecture while demonstrating the feasibility of AI-powered multi-modal content understanding in production environments.

% \section{Resources and Infrastructure Requirements}

% \subsection{Hardware Infrastructure}
% \begin{itemize}
%     \item \textbf{Development Workstations}: High-performance machines with minimum 32GB RAM, 8-core processors, and a GPU (with 24GB vram) support for ML model training and development, Simulating and Load Testing P2P network 
%     \item \textbf{Decentralized Testing Cluster}: 8-12 node setup with heterogeneous configurations to simulate real-world deployment scenarios 
% \end{itemize}

% \subsection{Cloud and External Services}
% \begin{itemize}
%     \item Cloud Compute, if required
%     \item \textbf{API Services}: OpenAI API access, Google Cloud AI APIs for benchmarking, General API and credentials (OAuth, Cloud Moderation etc.) for Production Grade application development 
% \end{itemize}


\section{Tech Stack}

\subsection{Backend \& Network Infrastructure}
\begin{itemize}
    \item \textbf{Core Language}: Golang for local-first application logic and integration of AI/ML components
    \item \textbf{Network and Communication}: go-libp2p-kad-dht (or similar custom implementation) for discovery and network routing
    \item \textbf{Database Layer}: SQLite/PostgreSQL for metadata storage, vector databases (Milvus/FAISS) for embeddings
    \item \textbf{Caching System}: Redis (Modularized) for high-performance caching and session management
\end{itemize}

\subsection{AI/ML Components}
\begin{itemize}
    \item \textbf{NLP Frameworks}: Hugging Face Transformers library with models like BERT, RoBERTa, T5 for semantic understanding and query processing
    \item \textbf{Embedding Generation}: Sentence-Transformers (e.g., all-MiniLM, paraphrase models) for efficient and compact semantic vector representations
    \item \textbf{Embedding Optimization}: Techniques for dimensionality reduction, quantization, and indexing using FAISS and Milvus
    \item \textbf{Computer Vision}: OpenCV and PIL for preprocessing; CLIP for cross-modal (image-text) embedding and similarity
    \item \textbf{Multimodal Learning}: Integration of image, text, and video embeddings for unified search and retrieval
\end{itemize}

\subsection{Client-side UI and Frontend}
\begin{itemize}
    \item \textbf{Executable Binaries}: Golang Binary Executables with Cobra CLI
    \item \textbf{Frontend Framework}: React.js for user interface development
\end{itemize}

\section{Team Composition and Expertise Requirements}

\subsection{Optimal Team Structure}
\textbf{Recommended Team Size}: 7 enthusiastic and curious members, with interests across AI/ML, backend development, networking, DevOps, and frontend/UI.  
While roles are defined for clarity, the team is encouraged to learn across domains and collaborate freely.

\subsection{Core Team Roles and Responsibilities}

\subsubsection{AI/ML Research Engineers}
\begin{itemize}
    \item \textbf{Primary Responsibilities}:
    \begin{itemize}
        \item Design and optimize semantic embedding pipelines for heterogeneous data types including text, images, and videos
        \item Develop advanced natural language processing modules for semantic query understanding, document ranking, and content summarization
        \item Architect and implement AI agents capable of multimodal content analysis, enabling unified search across diverse file formats
        \item Integrate and fine-tune vector-based similarity search mechanisms to support fast and context-aware retrieval in decentralized environments
    \end{itemize}
    
    \item \textbf{Learning Opportunities}:
    \begin{itemize}
        \item Direct involvement in the end-to-end development of intelligent retrieval systems operating over decentralized, peer-to-peer architectures
        \item In-depth exposure to state-of-the-art multimodal learning techniques, including cross-modal representation alignment and scalable vector-based retrieval frameworks
        \item Active contribution to a research-intensive, open-source initiative advancing the integration of natural language processing, computer vision, and distributed systems for next-generation AI applications
    \end{itemize}
\end{itemize}


\subsubsection{Backend and Networking Developers}
\begin{itemize}
    \item \textbf{Primary Responsibilities}:
    \begin{itemize}
        \item Build core backend logic integrating local search with a distributed P2P protocol
        \item Help design the federated tag-based query routing system
        \item Implement APIs, file retrieval, and metadata serving
    \end{itemize}
    \item \textbf{Learning Opportunities}:
    \begin{itemize}
        \item Work on a scalable, intelligent system using real backend patterns
        \item Understand decentralization, content routing, and federated search design
    \end{itemize}
\end{itemize}

\subsubsection{UI/UX and Frontend Developer}
\begin{itemize}
    \item \textbf{Primary Responsibilities}:
    \begin{itemize}
        \item Design and implement user-facing interfaces — CLI tools and/or web-based clients
        \item Ensure the search experience is intuitive, usable, and accessible
        \item Integrate metadata previews, search bar UX, file downloads, and more
    \end{itemize}
    \item \textbf{Learning Opportunities}:
    \begin{itemize}
        \item Understand the frontend side of an intelligent system
        \item Create usable tools over decentralized protocols
    \end{itemize}
\end{itemize}

\subsection{Note on Collaboration and Learning}
While the roles above are defined to organize efforts and expertise areas, every team member is encouraged to:
\begin{itemize}
    \item Learn from adjacent domains
    \item Participate in cross-functional problem solving
    \item Contribute wherever your curiosity takes you
    \item \textbf{Spoon-feeding is not expected}
\end{itemize}
This is an open-source, learning-driven project — the goal is growth, exposure, and building something awesome together.

\section{Milestones and Timeline}

\subsection{Overview}
The development of FileNest will be carried out in two parallel tracks:
\begin{enumerate}
    \item \textbf{Track 1 – Local Intelligent Search Engine:} Building an agentic AI-based system to index and search files locally using embeddings.
    \item \textbf{Track 2 – Nesting Protocol and Network Layer:} Developing a federated, tag-based P2P protocol for decentralized querying and retrieval.
\end{enumerate}

Both tracks will progress simultaneously with active collaboration and even switching among team members, coordinated by mentors to ensure modularity, interoperability, and a strong learning-driven development experience.

\subsection{Timeline Breakdown (12 Weeks)}

\begin{itemize}
    \item \textbf{Week 1: Learning and Planning Phase}
    \begin{itemize}
        \item All mentees onboarded with basics of ML, embeddings, P2P systems, backend architecture, and DevOps
        \item Mentors define and finalize architecture, module plan, and target technologies
        \item Establish internal documentation and shared knowledge base
    \end{itemize}

    \item \textbf{Week 2: Environment Setup and Protocol Design}
    \begin{itemize}
        \item Set up dev environments, tools, and repos
        \item Define modular code structure and interface formats for message passing, metadata representation, and file embedding schemas
        \item All mentees onboarded with task-specific knowledge, programming language and concepts
        \item Establish coding practices, documentation guidelines, and GitHub workflows
        \item Begin scaffolding core components of both tracks
    \end{itemize}

    \item \textbf{Week 3-6: Parallel Module Development}
    \begin{itemize}
        \item \textbf{Track 1}: Implement agentic AI-based local file analysis and indexing (text, image, video)
        \item \textbf{Track 2}: Begin implementation of basic P2P layer, including node communication and tag-based routing hierarchy
        \item Conduct daily or near-daily syncs to maintain alignment across tracks
        \item Each module to be tested and documented upon completion
    \end{itemize}

    \item \textbf{Week 7-8: System Testing and Integration Prep}
    \begin{itemize}
        \item Test local search engine independently for accuracy, speed, and usability
        \item Simulate the network on a single machine using multiple processes to verify nesting and routing logic
        \item Begin testing over LAN with multiple machines for OS and hardware compatibility
    \end{itemize}

    \item \textbf{Week 9: System Integration and LAN Testing}
    \begin{itemize}
        \item Integrate both tracks into a unified system
        \item Ensure seamless communication between local search and network query layer
        \item Use mDNS for peer discovery within LAN
        \item Conduct preliminary full-system LAN tests
    \end{itemize}

    \item \textbf{Week 10: Optimization and Load Testing}
    \begin{itemize}
        \item Identify potential optimizations across both AI and network components
        \item Conduct stress and load testing to evaluate system limits
        \item Compare results with expected benchmarks and document performance
    \end{itemize}

    \item \textbf{Week 11-12: Deployment and Finalization}
    \begin{itemize}
        \item Implement advanced network abstractions to support deployment beyond LAN (e.g., NAT traversal, optional relays)
        \item Deploy working prototype over cloud or public testbed
        \item Set up CI/CD pipelines and finalize project documentation
        \item Prepare project showcase, tutorials, and demo materials
    \end{itemize}
\end{itemize}

\hfill
\section{Learning Resources}
% \noindent\textbf{For further learning:}
\begin{itemize}
    \item \href{https://sebastianraschka.com/blog/2021/dl-course.html}{\underline{\texttt{\textbf{Deep Learning Fundamentals by Sebastian Raschka}}}}
    \item \href{https://www.coursera.org/learn/nlp-sequence-models}{\underline{\texttt{\textbf{Sequence Models (Deep Learning Specialization) by Andrew Ng}}}}
    \item \href{https://www.youtube.com/watch?v=2v6KqRB7adg&t=3s&pp=ygUMcGVlciB0byBwZWVy}{\underline{\texttt{\textbf{How Peer to Peer (P2P) Network works}}}}
     \item \href{https://www.youtube.com/watch?v=bBC-nXj3Ng4&t=1s&pp=ygURaG93IGJpdGNvaW4gd29ya3M%3D}{\underline{\texttt{\textbf{But how does Bitcoin actually work? | 3Blue1Brown}}}}
    
\end{itemize}

\vfill

\begin{figure}[b]
    \centering
    \includegraphics[width=0.2\textwidth]{logos/raid_logo.png}
\end{figure}


\begin{center}

Submitted to \textbf{Summer RAID 2025}\\
\textbf{Realm of Artificial Intelligence and Data}
\end{center}


\end{document}