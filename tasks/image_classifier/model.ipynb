{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc0632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchinfo as info\n",
    "import data\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "seed = 42\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1dcc61e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BottleneckLayer(nn.Module):\n",
    "    def __init__(self, in_c, out_c, exp_f, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_res_connect = (stride == 1 and in_c == out_c)\n",
    "        mid_c = in_c * exp_f\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(in_c, mid_c, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_c),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "\n",
    "            nn.Conv2d(mid_c, mid_c, kernel_size=3, stride=stride,\n",
    "                      padding=1, groups=mid_c, bias=False),\n",
    "            nn.BatchNorm2d(mid_c),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            # 1x1 projection\n",
    "            nn.Conv2d(mid_c, out_c, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.block(x)\n",
    "        else:\n",
    "            return self.block(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "312d4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_c=1, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_c, 8, kernel_size=3, stride=1, padding=1)  # (1 → 4)\n",
    "\n",
    "        self.block1 = BottleneckLayer(8, 16, exp_f=2, stride=2)               # (4 → 8)\n",
    "        self.block2 = BottleneckLayer(16, 16, exp_f=2, stride=1)               # (8 → 8)\n",
    "        self.block3 = BottleneckLayer(16, 32, exp_f=2, stride=2)              # (8 → 16)\n",
    "        self.block4 = BottleneckLayer(32, 32, exp_f=2, stride=1)             # (16 → 16)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))                             # (B, 16, 1, 1)\n",
    "        self.fc = nn.Linear(32, num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4421b015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "Model                                    --\n",
      "├─Conv2d: 1-1                            80\n",
      "├─BottleneckLayer: 1-2                   --\n",
      "│    └─Sequential: 2-1                   --\n",
      "│    │    └─Conv2d: 3-1                  128\n",
      "│    │    └─BatchNorm2d: 3-2             32\n",
      "│    │    └─ReLU6: 3-3                   --\n",
      "│    │    └─Conv2d: 3-4                  144\n",
      "│    │    └─BatchNorm2d: 3-5             32\n",
      "│    │    └─ReLU6: 3-6                   --\n",
      "│    │    └─Conv2d: 3-7                  256\n",
      "│    │    └─BatchNorm2d: 3-8             32\n",
      "├─BottleneckLayer: 1-3                   --\n",
      "│    └─Sequential: 2-2                   --\n",
      "│    │    └─Conv2d: 3-9                  512\n",
      "│    │    └─BatchNorm2d: 3-10            64\n",
      "│    │    └─ReLU6: 3-11                  --\n",
      "│    │    └─Conv2d: 3-12                 288\n",
      "│    │    └─BatchNorm2d: 3-13            64\n",
      "│    │    └─ReLU6: 3-14                  --\n",
      "│    │    └─Conv2d: 3-15                 512\n",
      "│    │    └─BatchNorm2d: 3-16            32\n",
      "├─BottleneckLayer: 1-4                   --\n",
      "│    └─Sequential: 2-3                   --\n",
      "│    │    └─Conv2d: 3-17                 512\n",
      "│    │    └─BatchNorm2d: 3-18            64\n",
      "│    │    └─ReLU6: 3-19                  --\n",
      "│    │    └─Conv2d: 3-20                 288\n",
      "│    │    └─BatchNorm2d: 3-21            64\n",
      "│    │    └─ReLU6: 3-22                  --\n",
      "│    │    └─Conv2d: 3-23                 1,024\n",
      "│    │    └─BatchNorm2d: 3-24            64\n",
      "├─BottleneckLayer: 1-5                   --\n",
      "│    └─Sequential: 2-4                   --\n",
      "│    │    └─Conv2d: 3-25                 2,048\n",
      "│    │    └─BatchNorm2d: 3-26            128\n",
      "│    │    └─ReLU6: 3-27                  --\n",
      "│    │    └─Conv2d: 3-28                 576\n",
      "│    │    └─BatchNorm2d: 3-29            128\n",
      "│    │    └─ReLU6: 3-30                  --\n",
      "│    │    └─Conv2d: 3-31                 2,048\n",
      "│    │    └─BatchNorm2d: 3-32            64\n",
      "├─AdaptiveAvgPool2d: 1-6                 --\n",
      "├─Linear: 1-7                            320\n",
      "=================================================================\n",
      "Total params: 9,504\n",
      "Trainable params: 9,504\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "model = Model().to(device=device)\n",
    "print(info.summary(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7b3cba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters() , lr= 0.001)\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "76eb88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, criterion, optimizer, device, epochs=10):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(xb)\n",
    "            loss = criterion(outputs, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * xb.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_correct += (predicted == yb).sum().item()\n",
    "            train_total += yb.size(0)\n",
    "\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        avg_train_loss = train_loss / train_total\n",
    "\n",
    "        # --- Evaluation on Test Set ---\n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in test_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                outputs = model(xb)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_correct += (predicted == yb).sum().item()\n",
    "                test_total += yb.size(0)\n",
    "\n",
    "        test_acc = 100 * test_correct / test_total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_train_loss:.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "43f829b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 0.4815 | Train Acc: 86.17% | Test Acc: 95.91%\n",
      "Epoch 2/10 | Loss: 0.1043 | Train Acc: 96.97% | Test Acc: 97.90%\n",
      "Epoch 3/10 | Loss: 0.0734 | Train Acc: 97.79% | Test Acc: 98.17%\n",
      "Epoch 4/10 | Loss: 0.0592 | Train Acc: 98.20% | Test Acc: 98.27%\n",
      "Epoch 5/10 | Loss: 0.0500 | Train Acc: 98.47% | Test Acc: 98.40%\n",
      "Epoch 6/10 | Loss: 0.0457 | Train Acc: 98.58% | Test Acc: 98.44%\n",
      "Epoch 7/10 | Loss: 0.0418 | Train Acc: 98.69% | Test Acc: 98.51%\n",
      "Epoch 8/10 | Loss: 0.0363 | Train Acc: 98.83% | Test Acc: 98.74%\n",
      "Epoch 9/10 | Loss: 0.0353 | Train Acc: 98.85% | Test Acc: 98.77%\n",
      "Epoch 10/10 | Loss: 0.0340 | Train Acc: 98.86% | Test Acc: 98.68%\n"
     ]
    }
   ],
   "source": [
    "train(model , data.train_loader , data.test_loader , criterion , optim , device , epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd63572c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
