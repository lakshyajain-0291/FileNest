# ğŸ“¦ FileNest: Concurrent File Embedding & Clustering

A lightweight Go-based concurrent file processing system that reads text files from a directory, generates random embedding vectors for each, assigns them to the closest pre-generated D1TV cluster (based on cosine similarity), and saves the metadata into a PostgreSQL database.

Built using a worker pool pattern with goroutines, context-based graceful shutdown, and PostgreSQL insertion via pgx.

---

## ğŸ“‚ Project Structure

.
â”œâ”€â”€ main.go                â†’ Main entry point, starts worker pool and processes jobs
â”œâ”€â”€ db/
â”‚   â””â”€â”€ db.go              â†’ Database connection management using pgx
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ d1tvs.go           â†’ Pre-generated cluster vectors (D1TVs)
â”‚   â””â”€â”€ models.go          â†’ File metadata struct
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ context.go         â†’ Graceful shutdown context using signals
â”œâ”€â”€ worker/
â”‚   â””â”€â”€ worker.go          â†’ Worker pool logic and file processing routines
â”œâ”€â”€ .env                   â†’ Environment variables for DB connection
â”œâ”€â”€ sample-data/           â†’ Directory for sample text files
â””â”€â”€ README.md              â†’ README.md file

---

## ğŸš€ How to Run

### Prerequisites

- Go 1.21+
- PostgreSQL running locally
- A `.env` file with:

DATABASE_URL=postgres://username:password@localhost:5432/databasename?sslmode=disable

### Install dependencies

go mod tidy

### Run the program

go run main.go sample-data/

This will:
- Process all `.txt` files inside `sample-data/`
- Generate a 128-dimensional random embedding for each
- Assign each file to the nearest D1TV cluster based on cosine similarity
- Store metadata into PostgreSQL database

---

## ğŸ“Š Database Schema

CREATE TABLE files (
  id SERIAL PRIMARY KEY,
  filename TEXT,
  filepath TEXT,
  embedding FLOAT8[],
  d1tv_id INT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

---

## âš™ï¸ How It Works

1. **Setup Context**
   - A cancellation context listens for system signals like `Ctrl+C` or termination signals for graceful shutdown.

2. **Database Connection**
   - PostgreSQL connection established via pgx, configured using `.env`.

3. **D1TV Initialization**
   - Pre-generate cluster vectors (D1TVs) for cosine similarity comparisons.

4. **Worker Pool Creation**
   - Spin up 5 worker goroutines via a channel-based worker pool.

5. **Job Distribution**
   - Walk through all `.txt` files inside the given directory, create a job for each, and send it to the worker pool.

6. **Embedding + Clustering**
   - Each worker reads file content, generates a 128-dim random embedding, finds the closest D1TV using cosine similarity, and inserts the metadata into the database.

7. **Wait for Completion**
   - The main routine waits for all worker goroutines to finish processing.

---

## ğŸ“š Concepts Used

- Worker Pool pattern using goroutines + channels
- Context cancellation and graceful shutdown
- Embedding generation via random vectors
- Cosine similarity for clustering
- Concurrent PostgreSQL insertion with pgx
- Environment variable management via godotenv

---

## ğŸ“ˆ Possible Extensions

- Replace random embeddings with real embeddings from Sentence Transformers, CLIP, or other AI models.
- Add intelligent error handling, logging, and retry logic.
- Implement file deduplication using file content hash.
- Build a CLI interface for user-friendly file indexing.
- Optionally replace pgx with GORM for ORM-style database handling.

---

## ğŸ“ License

MIT License
